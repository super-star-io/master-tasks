{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69b00228",
   "metadata": {},
   "source": [
    "### Carga de librerias necesarias para el analisis multivariante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "511fa34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Mar  1 12:07:43 2019\n",
    "\n",
    "\"\"\"\n",
    "#==============================================================================\n",
    "# EJEMPLO DEL MÉTODO DE REGRESIÓN LINEAL SIMPLE USANDO LAS LIBRERÍAS \n",
    "# SKLEARN Y STATSMODELS (EJEMPLO 1)\n",
    "#==============================================================================\n",
    "\n",
    "# Cargar librerías\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00e6cf7",
   "metadata": {},
   "source": [
    "### Se Carga el dataset epilepsy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7917f08",
   "metadata": {},
   "source": [
    "Este conjunto de datos proporciona una extensa recopilación de atributos clínicos, neurológicos, conductuales y relacionados con el estilo de vida de las personas con epilepsia. Incluye información demográfica (edad, sexo, peso, altura), historial médico (estado de medicación, exploraciones cerebrales, trastornos genéticos, antecedentes de accidentes cerebrovasculares y traumatismos craneoencefálicos), características específicas de las convulsiones (frecuencia, duración, tipo, aura y efectos postictales) y posibles desencadenantes de las convulsiones (privación de sueño, estrés, omisión de medicación, sensibilidad a la luz y al sonido). Diseñado para respaldar la investigación y las aplicaciones de aprendizaje automático, este conjunto de datos busca facilitar una clasificación precisa y una comprensión más profunda de los tipos de epilepsia y sus factores contribuyentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3994de6",
   "metadata": {},
   "source": [
    "Explicacion de variables\n",
    "\n",
    "* **Age:** Edad de la persona en años.(Numerica)\n",
    "* **Gender:** Sexo de la persona.(Categorica)\n",
    "* **Weight:** Peso de la persona en kilogramos.\n",
    "* **Height:** Altura de la persona en metros.\n",
    "* **Medication Status:** Estado de medicación de la persona (si está tomando medicación para la epilepsia o no).(Categorica)\n",
    "* **Alcohol or Drug Use:** Uso de alcohol o drogas en la persona (sí o no).\n",
    "* **EEG Abnormality Detected:** Detección de anomalía en el EEG de la persona (sí o no).\n",
    "* **MRI/CT Scan Result:** Resultado de la exploración MRI o CT de la persona.(Categorica)\n",
    "* **Seizure Frequency:** Frecuencia de convulsiones de la persona.\n",
    "* **Seizure Duration:** Duración de las convulsiones de la persona en segundos.\n",
    "* **Seizure Type:** Tipo de convulsión de la persona (por ejemplo, simple, múltiple, atípica).\n",
    "* **Aura Before Seizure:** Aura de la persona antes de la convulsión (si la persona tiene aura o no) (Categorica)\n",
    "* **Loss of Consciousness:** Perdida de consciencia de la persona durante la convulsión (sí o no).(Categorica)\n",
    "* **Muscle Stiffness:** Estiffidad de los músculos de la persona durante la convulsión (sí o no).(Categorica)\n",
    "* **Jerky Movements:** Movimientos bruscos de la persona durante la convulsión (sí o no).(Categorica)\n",
    "* **Postictal Confusion:** Confusión postictal de la persona después de la convulsión (sí o no).(Categorica)\n",
    "* **Blank Stare Episodes:** Número de episodios de foco en blanco de la persona después de la convulsión.(Categorica)\n",
    "* **Eye Rolling:** Movimientos de los ojos de la persona durante la convulsión (sí o no).(Categorica)\n",
    "* **Stress or Anxiety Before Episode:** Estrés o ansiedad de la persona antes de la convulsión (sí o no).(Categorica)\n",
    "* **Lack of Sleep Before Episode:** Falta de sueño de la persona antes de la convulsión (sí o no).(Categorica)\n",
    "* **Flashing Lights Sensitivity:** Sensibilidad de la persona a los luces flashantes (sí o no).(Categorica)\n",
    "* **Loud Sound Sensitivity:** Sensibilidad de la persona a los sonidos fuertes (sí o no).(Categorica)\n",
    "* **Missed Medication:** Faltas de medicación de la persona para la epilepsia (sí o no).(Categorica)\n",
    "* **Family History of Epilepsy:** Antecedentes familiares de epilepsia de la persona (sí o no).(Categorica)\n",
    "* **Head Injury History:** Historial de lesiones en la cabeza de la persona (sí o no).(Categorica)\n",
    "* **Brain Tumor:** Historial de tumores cerebrales de la persona (sí o no).(Categorica)\n",
    "* **History of Stroke:** Historial de accidentes cerebrovasculares de la persona (sí o no).(Categorica)\n",
    "* **Genetic Disorder:** Historial de trastornos genéticos de la persona (sí o no).(Categorica)\n",
    "* **Developmental Delay (in Children):** Retraso en el desarrollo de la persona en niños (sí o no).(Categorica)\n",
    "* **Target/Epilepsy Type:** Tipo de epilepsia de la persona (por ejemplo, simple, múltiple, atípica).(Categorica)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bd5fb0",
   "metadata": {},
   "source": [
    "### Carga el DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe428f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                                  0\n",
      "Gender                               0\n",
      "Weight                               0\n",
      "Height                               0\n",
      "Medication_Status                    0\n",
      "Alcohol_or_Drug_Use                  0\n",
      "EEG_Abnormality_Detected             0\n",
      "MRI/CT_Scan_Result                   0\n",
      "Seizure_Frequency                    0\n",
      "Seizure_Duration                     0\n",
      "Seizure_Type                         0\n",
      "Aura_Before_Seizure                  0\n",
      "Loss_of_Consciousness                0\n",
      "Muscle_Stiffness                     0\n",
      "Jerky_Movements                      0\n",
      "Postictal_Confusion                  0\n",
      "Blank_Stare_Episodes                 0\n",
      "Eye_Rolling                          0\n",
      "Stress_or_Anxiety_Before_Episode     0\n",
      "Lack_of_Sleep_Before_Episode         0\n",
      "Flashing_Lights_Sensitivity          0\n",
      "Loud_Sound_Sensitivity               0\n",
      "Missed_Medication                    0\n",
      "Family_History_of_Epilepsy           0\n",
      "Head_Injury_History                  0\n",
      "Brain_Tumor                          0\n",
      "History_of_Stroke                    0\n",
      "Genetic_Disorder                     0\n",
      "Developmental_Delay_(in_Children)    0\n",
      "Target/Epilepsy_Type                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('./Epilepsy_dataset.csv') # Cargar dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69502c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age  Gender  Weight  Height  Medication_Status  Alcohol_or_Drug_Use  \\\n",
      "0      15     1.0    48.3   168.2                  1                    1   \n",
      "1       4     0.0    56.0   174.5                  1                    0   \n",
      "2      36     0.0    44.8   156.2                  1                    0   \n",
      "3      32     0.0    70.4   180.4                  0                    0   \n",
      "4      29     1.0    54.5   161.7                  1                    0   \n",
      "...   ...     ...     ...     ...                ...                  ...   \n",
      "4851   76     0.0    58.1   170.3                  1                    0   \n",
      "4852   10     1.0    80.6   172.9                  1                    1   \n",
      "4853   67     1.0    37.0   159.6                  1                    0   \n",
      "4854   33     1.0    54.7   156.5                  1                    0   \n",
      "4855   49     1.0    83.0   172.4                  0                    0   \n",
      "\n",
      "      EEG_Abnormality_Detected  Seizure_Frequency  Seizure_Duration  \\\n",
      "0                            1                  1                60   \n",
      "1                            1                  1                30   \n",
      "2                            1                  3                30   \n",
      "3                            1                  0                60   \n",
      "4                            1                  1                60   \n",
      "...                        ...                ...               ...   \n",
      "4851                         1                  0                60   \n",
      "4852                         1                  2                60   \n",
      "4853                         1                  1               120   \n",
      "4854                         0                  2                90   \n",
      "4855                         0                  3                60   \n",
      "\n",
      "      Aura_Before_Seizure  ...  Flashing_Lights_Sensitivity  \\\n",
      "0                       0  ...                            1   \n",
      "1                       1  ...                            0   \n",
      "2                       1  ...                            0   \n",
      "3                       1  ...                            1   \n",
      "4                       0  ...                            0   \n",
      "...                   ...  ...                          ...   \n",
      "4851                    1  ...                            1   \n",
      "4852                    0  ...                            1   \n",
      "4853                    0  ...                            0   \n",
      "4854                    0  ...                            0   \n",
      "4855                    1  ...                            1   \n",
      "\n",
      "      Loud_Sound_Sensitivity  Missed_Medication  Family_History_of_Epilepsy  \\\n",
      "0                          1                  0                           0   \n",
      "1                          0                  0                           1   \n",
      "2                          1                  1                           1   \n",
      "3                          1                  0                           0   \n",
      "4                          1                  0                           1   \n",
      "...                      ...                ...                         ...   \n",
      "4851                       0                  0                           1   \n",
      "4852                       0                  0                           0   \n",
      "4853                       0                  0                           1   \n",
      "4854                       1                  0                           0   \n",
      "4855                       0                  0                           1   \n",
      "\n",
      "      Head_Injury_History  Brain_Tumor  History_of_Stroke  Genetic_Disorder  \\\n",
      "0                       0            0                  0                 0   \n",
      "1                       1            1                  0                 0   \n",
      "2                       0            0                  0                 0   \n",
      "3                       0            0                  0                 0   \n",
      "4                       0            1                  0                 0   \n",
      "...                   ...          ...                ...               ...   \n",
      "4851                    0            0                  0                 1   \n",
      "4852                    1            0                  0                 1   \n",
      "4853                    0            0                  0                 1   \n",
      "4854                    1            0                  0                 0   \n",
      "4855                    0            0                  0                 0   \n",
      "\n",
      "      Developmental_Delay_(in_Children)  Target/Epilepsy_Type  \n",
      "0                                     1           Generalized  \n",
      "1                                     0           Generalized  \n",
      "2                                     0           Generalized  \n",
      "3                                     0                 Focal  \n",
      "4                                     0           Generalized  \n",
      "...                                 ...                   ...  \n",
      "4851                                  0           Generalized  \n",
      "4852                                  0           Generalized  \n",
      "4853                                  0           Generalized  \n",
      "4854                                  0           Generalized  \n",
      "4855                                  0                 Focal  \n",
      "\n",
      "[4856 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# Conversión de variables categoricas a numericas\n",
    "# Convertimos la capos con valores 'yes' o 'no' a (0 y 1)\n",
    "# 'Alcohol or Drug Use','EEG Abnormality Detected', 'Aura Before Seizure', 'Loss of Consciousness', 'Muscle Stiffness', 'Jerky Movements', 'Postictal Confusion', 'Blank Stare Episodes', 'Eye Rolling', 'Stress or Anxiety Before Episode', 'Lack of Sleep Before Episode', 'Flashing Lights Sensitivity', 'Loud Sound Sensitivity', 'Missed Medication', 'Family History of Epilepsy', 'Head Injury History', 'Brain Tumor', 'History of Stroke', 'Genetic Disorder', 'Developmental Delay (in Children)'\n",
    "\n",
    "categorical_cols = dataset.select_dtypes(include=['object']).columns.tolist() # Identifica variables categoricas\n",
    "numeric_cols = dataset.select_dtypes(include=['int64', 'float64']).columns.tolist() # Identifica variables numericas\n",
    "\n",
    "for col in categorical_cols: # Recorre cada columna categorica\n",
    "    if col != 'Medication_Status' and col != 'Gender' and col != 'MRI/CT_Scan_Result' and col != 'Target/Epilepsy_Type': # Excluye las columnas que no se convierten\n",
    "        dataset[col] = dataset[col].map({'No': 0, 'Yes': 1}) # Convierte 'No' y 'Yes' a 0 y 1\n",
    "\n",
    "dataset['Medication_Status'] = dataset['Medication_Status'].map({'Not on Medication': 0, 'On Medication': 1}) # Convierte 'Not on Medication' y 'On Medication' a 0 y 1\n",
    "dataset['Gender'] = dataset['Gender'].map({'Female': 0, 'Male': 1}) # Convierte 'Female' y 'Male' a 0 y 1\n",
    "dataset.drop(columns=['MRI/CT_Scan_Result'], inplace=True) # Elimina la columna 'MRI/CT_Scan_Result'\n",
    "dataset.drop(columns=['Seizure_Type'], inplace=True) # Elimina la columna 'Seizure_Type'\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5011ac34",
   "metadata": {},
   "source": [
    "### Segmenta las variables independientes (X) y la variable dependiente (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aecdda0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables independientes (X):\n",
      "[[15.   1.  48.3 ...  0.   0.   1. ]\n",
      " [ 4.   0.  56.  ...  0.   0.   0. ]\n",
      " [36.   0.  44.8 ...  0.   0.   0. ]\n",
      " ...\n",
      " [67.   1.  37.  ...  0.   1.   0. ]\n",
      " [33.   1.  54.7 ...  0.   0.   0. ]\n",
      " [49.   1.  83.  ...  0.   0.   0. ]]\n",
      "\n",
      "Variable dependiente (y):\n",
      "['Generalized' 'Generalized' 'Generalized' ... 'Generalized' 'Generalized'\n",
      " 'Focal']\n"
     ]
    }
   ],
   "source": [
    "X = dataset.iloc[:, :-1].values # Todas las filas (variables independientes), todas las columnas excepto la última\n",
    "y = dataset.iloc[:, -1].values # Todas las filas (variable dependiente), última columna\n",
    "\n",
    "print(\"Variables independientes (X):\")\n",
    "print(X)\n",
    "print(\"\\nVariable dependiente (y):\")\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5debb2b3",
   "metadata": {},
   "source": [
    "# Dividir el dataset en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf080ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2e5d36",
   "metadata": {},
   "source": [
    "### Escalar variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1919223c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'isnull'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#print(y_train, y_test)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m nan_counts_x_train \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnull\u001b[49m()\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     14\u001b[0m nan_counts_y_test \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(nan_counts_x_train, nan_counts_y_test)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'isnull'"
     ]
    }
   ],
   "source": [
    "# Escalar variables\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.fit_transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#print(X_train, X_test)\n",
    "print('------------------------------------')\n",
    "#print(y_train, y_test)\n",
    "\n",
    "nan_counts_x_train = X_train.isnull().sum()\n",
    "nan_counts_y_test = X_test.isnull().sum()\n",
    "\n",
    "print(nan_counts_x_train, nan_counts_y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a084fd8",
   "metadata": {},
   "source": [
    "### Crear Modelo de regresion lineal sumple con el conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9aa733e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m regression \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mregression\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_base.py:601\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    597\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[1;32m    599\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 601\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    611\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:2961\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m   2960\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2961\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:1370\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1366\u001b[0m     )\n\u001b[1;32m   1368\u001b[0m ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[0;32m-> 1370\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1387\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1389\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:1107\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[0;32m-> 1107\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1116\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:169\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m     )\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "regression = LinearRegression()\n",
    "regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f19715",
   "metadata": {},
   "source": [
    "# Predecir con el conjunto de prueba y el modelo de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2691a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regression.predict(X_test)\n",
    "\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
